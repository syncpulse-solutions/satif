---
sidebar_position: 1
---
# Overview

> **SATIF is an AI toolkit for simplifying and automating the transformation of ANY input files into ANY output files.**

## Core Architecture

SATIF utilizes a two-layer architecture:

1. **Standardization Layer**: Ingests heterogeneous source files (CSV, Excel, PDF, XML, etc.) and transforms them into SDIF, a structured intermediate format.
2. **Transformation Layer**: Applies business logic to the standardized data to generate the target output files, with transformation code either written manually or generated by AI.

```mermaid
flowchart LR
    Start(Datasource Files) --> StdExec{"Standardization Executor"}

    subgraph StdLayer [Standardization Layer]
        direction LR
        StdExec --> SdifStd[("SDIF File")]
    end

    SdifStd --> TxExec{"Transformation Executor"}

    subgraph TxLayer [Transformation Layer]
        direction LR
        TxExec --> End(Output Files)
    end

    SdifSchema["(optional) sdif_schema"]
    SdifSchema -.-> StdExec

    %% Refined Dark Mode Style
    classDef default fill:#3a3a3a,color:#dddddd,stroke-width:1px;
    classDef executorNode fill:#4a4a88,stroke:#aaccaa,color:#eeeeff;
    classDef sdifNode fill:#886a4a,stroke:#ffccaa,color:#ffffee;
    classDef ioNode fill:#555555,stroke:#aaaaaa,color:#dddddd;
    classDef layerSubgraph fill:#2f2f2f,stroke:#666666,color:#cccccc;
    classDef schemaNode fill:#88884a,stroke:#ffffaa,color:#ffffee;

    class Start,End ioNode;
    class StdExec,TxExec executorNode;
    class SdifStd sdifNode;
    class SdifSchema schemaNode;
    class StdLayer,TxLayer layerSubgraph;
    style SdifStd stroke-width:2px;
```

## SDIF: The Intermediate Format

SDIF (Stantardized Data Interoperable Format) is the standardized SQLite representation that:

- Stores a [Datasource](terminology.md) as structured tables alongside JSON objects and binary media
- Maintains rich metadata about data origins, structure, and relationships
- Provides direct SQL queryability for complex transformations
- Creates a consistent interface between standardization and transformation

## Workflow

1. **BUILD**: Generate transformation code via AI based on example inputs/outputs and instructions
2. **RUN**: Execute the full pipeline (standardization â†’ transformation) on new inputs
3. **REFINE**: Iteratively improve the pipeline through feedback and error handling

```mermaid
flowchart TD
    classDef buildStyle fill:#334466, color:#FFFFFF, stroke:#A9A9A9, stroke-width:2px
    classDef runStyle fill:#336633, color:#FFFFFF, stroke:#A9A9A9, stroke-width:2px
    classDef refineStyle fill:#663333, color:#FFFFFF, stroke:#A9A9A9, stroke-width:2px
    classDef artifactStyle fill:#222222, color:#FFFFFF, stroke:#A9A9A9, stroke-width:1px
    classDef ioStyle fill:#444444, color:#FFFFFF, stroke:#A9A9A9

    subgraph Inputs
        UserInput["User Input (Examples, NL)"]:::ioStyle
        Datasource["Datasource (Files)"]:::ioStyle
    end

    subgraph SATIF_Cycles [SATIF System Cycles]
        direction LR
        BUILD["BUILD Cycle (Code Generation)"]:::buildStyle
        RUN["RUN Cycle (Pipeline Execution)"]:::runStyle
        Refine["Refinement Cycle"]:::refineStyle
    end

    subgraph Outputs
        GeneratedArtifacts["Generated Code Artifacts<br/>(.py)"]:::artifactStyle
        OutputFiles["Output Files"]:::ioStyle
    end

    UserInput -- Provides Specs --> BUILD
    Datasource -- Processed During --> RUN

    BUILD -- Produces --> GeneratedArtifacts
    GeneratedArtifacts -- Consumed By --> RUN
    GeneratedArtifacts -- Updated By --> Refine

    RUN -- Produces --> OutputFiles
    RUN -- Provides Feedback --> Refine
```

SATIF eliminates the need to write custom parsing logic, letting you focus on your business transformation requirements.

## Key Capabilities

- **Any Format Support**: Process virtually any input, even challenging unstructured content (PDFs, complex Excel sheets)
- **AI-Powered Code Generation**: Automatically generate transformation code from examples and natural language instructions
- **Robust Schema Enforcement**: Handle input data drift and schema inconsistencies through configurable validation
- **SQL-Based Data Processing**: Query and manipulate all data using SQL
- **Decoupled Processing Stages**: Standardize once, transform many times with different logic
