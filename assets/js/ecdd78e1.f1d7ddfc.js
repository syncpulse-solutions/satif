"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4536],{8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var r=t(6540);const s={},i=r.createContext(s);function o(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(i.Provider,{value:n},e.children)}},9052:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"transformers/code_transformer","title":"CodeTransformer","description":"The CodeTransformer is a component designed to execute custom Python code for transforming data stored in one or more SDIF files into various output file formats. It provides a flexible way to define and run data processing logic directly within your workflow.","source":"@site/docs/transformers/code_transformer.md","sourceDirName":"transformers","slug":"/transformers/code_transformer","permalink":"/satif/docs/transformers/code_transformer","draft":false,"unlisted":false,"editUrl":"https://github.com/syncpulse-solutions/satif/tree/main/docs/docs/transformers/code_transformer.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Transformers","permalink":"/satif/docs/transformers"},"next":{"title":"Transformation Builders","permalink":"/satif/docs/transformation-builders"}}');var s=t(4848),i=t(8453);const o={sidebar_position:3},a="CodeTransformer",c={},d=[{value:"1. Basic Usage",id:"1-basic-usage",level:2},{value:"2. Providing Transformation Logic",id:"2-providing-transformation-logic",level:2},{value:"3. The Transformation Function",id:"3-the-transformation-function",level:2},{value:"4. Handling Input SDIFs",id:"4-handling-input-sdifs",level:2},{value:"5. Exporting Results (<code>export</code> method)",id:"5-exporting-results-export-method",level:2},{value:"6. In-Memory Transformation (<code>transform</code> method)",id:"6-in-memory-transformation-transform-method",level:2},{value:"7. Advanced Configuration",id:"7-advanced-configuration",level:2},{value:"8. Error Handling",id:"8-error-handling",level:2}];function l(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"codetransformer",children:"CodeTransformer"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"CodeTransformer"})," is a component designed to execute custom Python code for transforming data stored in one or more SDIF files into various output file formats. It provides a flexible way to define and run data processing logic directly within your workflow."]}),"\n",(0,s.jsx)(n.h2,{id:"1-basic-usage",children:"1. Basic Usage"}),"\n",(0,s.jsxs)(n.p,{children:["The simplest way to use ",(0,s.jsx)(n.code,{children:"CodeTransformer"})," is by providing a Python function that performs the transformation."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Define your transformation function:"})}),"\n",(0,s.jsxs)(n.p,{children:["This function takes a ",(0,s.jsx)(n.code,{children:"sqlite3.Connection"})," object, which provides access to the input SDIF data attached as schemas (e.g., ",(0,s.jsx)(n.code,{children:"db1"}),"). It must return a dictionary where keys are relative output filenames and values are the data to be written (e.g., a pandas DataFrame)."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Example transformation function\nimport pandas as pd\nimport sqlite3\nfrom typing import Dict, Any\nfrom datetime import timedelta\n\ndef process_invoices(conn: sqlite3.Connection) -> Dict[str, Any]:\n    \"\"\"Reads invoices, calculates due dates, and returns a DataFrame.\"\"\"\n    df = pd.read_sql_query(\"SELECT * FROM db1.factures WHERE type = 'Facture'\", conn)\n\n    # Simple calculation example\n    df['IssueDateDT'] = pd.to_datetime(df['date_emission'])\n    df['DueDate'] = (df['IssueDateDT'] + timedelta(days=30)).dt.strftime('%Y-%m-%d')\n\n    # Select and rename columns\n    final_df = df[['id_facture', 'client', 'montant_ttc', 'DueDate']].rename(columns={\n        'id_facture': 'InvoiceID',\n        'client': 'Customer',\n        'montant_ttc': 'TotalAmount'\n    })\n\n    # Return dictionary: {output_filename: data_object}\n    return {\"processed_invoices.csv\": final_df}\n\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Instantiate and run the transformer:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from satif.transformers.code import CodeTransformer\nfrom pathlib import Path\n\n# Assume \'input_invoices.sdif\' exists\ninput_sdif_path = Path("input_invoices.sdif")\noutput_csv_path = Path("output/processed_invoices.csv")\n\n# 1. Create the transformer instance with the function\ntransformer = CodeTransformer(function=process_invoices)\n\n# 2. Execute the transformation and export the result\nresult_path = transformer.export(\n    sdif=input_sdif_path,\n    output_path=output_csv_path\n)\nprint(f"Transformation successful. Output written to: {result_path}")\n\n'})}),"\n",(0,s.jsxs)(n.p,{children:["This will execute the ",(0,s.jsx)(n.code,{children:"process_invoices"})," function using the data from ",(0,s.jsx)(n.code,{children:"input_invoices.sdif"})," (accessed as schema ",(0,s.jsx)(n.code,{children:"db1"}),") and write the resulting DataFrame to ",(0,s.jsx)(n.code,{children:"output/processed_invoices.csv"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"2-providing-transformation-logic",children:"2. Providing Transformation Logic"}),"\n",(0,s.jsx)(n.p,{children:"Besides passing a function object directly, you can provide the transformation logic in other ways:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"a) Code String:"})}),"\n",(0,s.jsxs)(n.p,{children:["Pass the Python code as a string. You might need to specify the function name if it's not the default (",(0,s.jsx)(n.code,{children:"transform"}),")."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'TRANSFORM_CODE = """\nimport pandas as pd\nimport sqlite3\n\n# Default function name is \'transform\'\ndef transform(conn: sqlite3.Connection):\n    df = pd.read_sql_query("SELECT client, SUM(montant_ht) as total_ht FROM db1.factures GROUP BY client", conn)\n    return {"client_summary.json": df}\n"""\n\ntransformer = CodeTransformer(function=TRANSFORM_CODE)\n# If function name was different, e.g., \'generate_summary\':\n# transformer = CodeTransformer(function=TRANSFORM_CODE, function_name="generate_summary")\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"b) File Path:"})}),"\n",(0,s.jsxs)(n.p,{children:["Provide a ",(0,s.jsx)(n.code,{children:"pathlib.Path"})," object pointing to a Python file containing the transformation function."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Assume 'my_transforms/invoice_logic.py' contains the 'process_invoices' function\ntransform_script_path = Path(\"my_transforms/invoice_logic.py\")\n\ntransformer = CodeTransformer(\n    function=transform_script_path,\n    function_name=\"process_invoices\" # Specify the function to run from the file\n)\n# ... then call transformer.export(...)\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:["c) Using the ",(0,s.jsx)(n.code,{children:"@transformation"})," Decorator:"]})}),"\n",(0,s.jsxs)(n.p,{children:["Decorate your transformation functions with ",(0,s.jsx)(n.code,{children:"@transformation"}),". This registers them internally, allowing you to instantiate ",(0,s.jsx)(n.code,{children:"CodeTransformer"})," using the function object or its registered name (which defaults to the function name)."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from satif.transformers.code import transformation\n\n@transformation\ndef generate_report(conn):\n    # ... logic ...\n    return {"report.txt": "Report content"}\n\n@transformation(name="custom_invoice_summary") # Register with a custom name\ndef create_invoice_summary(conn):\n    # ... logic ...\n    return {"summary.csv": df_summary}\n\n# Instantiate using the function object\ntransformer1 = CodeTransformer(function=generate_report)\n\n# Instantiate using the registered name (string)\ntransformer2 = CodeTransformer(function="custom_invoice_summary")\n\n# ... then call transformer.export(...) for each\n'})}),"\n",(0,s.jsx)(n.h2,{id:"3-the-transformation-function",children:"3. The Transformation Function"}),"\n",(0,s.jsx)(n.p,{children:"Your transformation code needs to adhere to specific requirements:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Signature:"})," Must accept at least one argument: ",(0,s.jsx)(n.code,{children:"conn: sqlite3.Connection"}),". It can optionally accept a second argument: ",(0,s.jsx)(n.code,{children:"context: Dict[str, Any]"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input Data Access:"})," Use the ",(0,s.jsx)(n.code,{children:"conn"})," object to query data from the attached SDIF files. Standard SQL queries (e.g., via ",(0,s.jsx)(n.code,{children:"pandas.read_sql_query"}),") work directly. Input SDIF files are attached as schemas (see Section 4)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return Value:"})," MUST return a dictionary (",(0,s.jsx)(n.code,{children:"Dict[str, Any]"}),").\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Keys:"})," Relative paths for the output files (e.g., ",(0,s.jsx)(n.code,{children:'"data/summary.csv"'}),", ",(0,s.jsx)(n.code,{children:'"report.json"'}),"). Subdirectories will be created automatically during export. Use POSIX-style separators (",(0,s.jsx)(n.code,{children:"/"}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Values:"})," The data to be written. Supported types include:\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"pandas.DataFrame"})}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"dict"})," or ",(0,s.jsx)(n.code,{children:"list"})," (will be saved as JSON)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"str"})," (will be saved as UTF-8 text)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"bytes"})," (will be saved as a binary file)"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"4-handling-input-sdifs",children:"4. Handling Input SDIFs"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"CodeTransformer"})," can process data from one or multiple SDIF files."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," Throughout this documentation, ",(0,s.jsx)(n.code,{children:"SDIFPath"})," refers to either a string path or a ",(0,s.jsx)(n.code,{children:"pathlib.Path"})," object pointing to an SDIF file."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"a) Single SDIF Path:"})}),"\n",(0,s.jsxs)(n.p,{children:["The default behavior shown previously. The data is accessible via the schema named ",(0,s.jsx)(n.code,{children:"db1"})," (or a custom prefix, see Advanced Configuration)."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'transformer.export(sdif="path/to/single.sdif", ...)\n# SQL: SELECT * FROM db1.my_table\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"b) List of SDIF Paths:"})}),"\n",(0,s.jsxs)(n.p,{children:["Provide a list of paths. They will be attached sequentially with default schema names ",(0,s.jsx)(n.code,{children:"db1"}),", ",(0,s.jsx)(n.code,{children:"db2"}),", etc."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'transformer.export(sdif=["invoices.sdif", "clients.sdif"], ...)\n# SQL: SELECT * FROM db1.invoices_table\n# SQL: SELECT * FROM db2.clients_table\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"c) Dictionary of Schema Names to Paths:"})}),"\n",(0,s.jsx)(n.p,{children:"Provide a dictionary mapping your desired schema names to their corresponding SDIF file paths. This gives you explicit control over schema naming in your SQL queries."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'transformer.export(\n    sdif={\n        "inv": "path/to/invoices.sdif",\n        "cust": "path/to/customers.sdif"\n    },\n    ...\n)\n# SQL: SELECT * FROM inv.invoices_table\n# SQL: SELECT i.*, c.name FROM inv.invoices_table i JOIN cust.info c ON i.cust_id = c.id\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:["d) Using an ",(0,s.jsx)(n.code,{children:"SDIFDatabase"})," Instance:"]})}),"\n",(0,s.jsxs)(n.p,{children:["If you already have an opened ",(0,s.jsx)(n.code,{children:"SDIFDatabase"})," object (from ",(0,s.jsx)(n.code,{children:"satif.sdif_database"}),"), you can pass it directly. The transformer will use its existing connection and schema name. The connection will ",(0,s.jsx)(n.em,{children:"not"})," be closed by the transformer in this case."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from satif.sdif_database import SDIFDatabase\n\n# Assume db is an initialized SDIFDatabase instance with schema_name=\'input_data\'\ndb = SDIFDatabase("my_data.sdif", read_only=True, schema_name="input_data")\ntry:\n    transformer.export(sdif=db, ...)\n    # SQL: SELECT * FROM input_data.some_table\nfinally:\n    db.close() # Remember to close the database connection yourself\n'})}),"\n",(0,s.jsxs)(n.h2,{id:"5-exporting-results-export-method",children:["5. Exporting Results (",(0,s.jsx)(n.code,{children:"export"})," method)"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"export"})," method takes the transformed data and writes it to the filesystem."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"sdif"}),":"]})," The input SDIF source(s) (as described above)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"output_path"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["If the transformation returns a ",(0,s.jsx)(n.em,{children:"single"})," output file and ",(0,s.jsx)(n.code,{children:"output_path"})," ",(0,s.jsx)(n.em,{children:"does not"})," point to an existing directory, ",(0,s.jsx)(n.code,{children:"output_path"})," is treated as the ",(0,s.jsx)(n.em,{children:"exact path"})," for that single output file."]}),"\n",(0,s.jsxs)(n.li,{children:["Otherwise, ",(0,s.jsx)(n.code,{children:"output_path"})," is treated as the ",(0,s.jsx)(n.em,{children:"base directory"})," where the output files (using the relative paths from the transformation result keys) will be written. If the directory doesn't exist, it will be created."]}),"\n",(0,s.jsxs)(n.li,{children:["Defaults to the current directory (",(0,s.jsx)(n.code,{children:"."}),")."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"zip_archive"})," (bool, default ",(0,s.jsx)(n.code,{children:"False"}),"):"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["If ",(0,s.jsx)(n.code,{children:"True"}),", all output files are written into a single ZIP archive named according to ",(0,s.jsx)(n.code,{children:"output_path"}),". In this case, ",(0,s.jsx)(n.code,{children:"output_path"})," ",(0,s.jsx)(n.em,{children:"must"})," be a file path (e.g., ",(0,s.jsx)(n.code,{children:'"output/archive.zip"'}),"), not a directory."]}),"\n",(0,s.jsxs)(n.li,{children:["If ",(0,s.jsx)(n.code,{children:"False"})," (default), files are written directly to the filesystem based on ",(0,s.jsx)(n.code,{children:"output_path"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"File Writing Behavior:"})}),"\n",(0,s.jsx)(n.p,{children:"The format used for writing depends on the file extension in the keys of the dictionary returned by your transformation function and the type of the data object:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:".csv"}),":"]})," Writes ",(0,s.jsx)(n.code,{children:"pandas.DataFrame"})," using ",(0,s.jsx)(n.code,{children:"to_csv(index=False)"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:".json"}),":"]})," Writes ",(0,s.jsx)(n.code,{children:"pandas.DataFrame"})," using ",(0,s.jsx)(n.code,{children:'to_json(orient="records", indent=2)'}),". Writes ",(0,s.jsx)(n.code,{children:"dict"})," or ",(0,s.jsx)(n.code,{children:"list"})," using ",(0,s.jsx)(n.code,{children:"json.dump(indent=2)"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:".xlsx"})," / ",(0,s.jsx)(n.code,{children:".xls"}),":"]})," Writes ",(0,s.jsx)(n.code,{children:"pandas.DataFrame"})," using ",(0,s.jsx)(n.code,{children:"to_excel(index=False)"}),". Requires optional dependencies (",(0,s.jsx)(n.code,{children:"openpyxl"})," for ",(0,s.jsx)(n.code,{children:".xlsx"}),").\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," You must install ",(0,s.jsx)(n.code,{children:"openpyxl"})," to write Excel files: ",(0,s.jsx)(n.code,{children:"pip install openpyxl"}),". If not installed, an ",(0,s.jsx)(n.code,{children:"ExportError"})," will be raised when attempting to write Excel files."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:".txt"})," (or other text-based):"]})," Writes ",(0,s.jsx)(n.code,{children:"str"})," content."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Binary extensions (e.g., ",(0,s.jsx)(n.code,{children:".bin"}),"):"]})," Writes ",(0,s.jsx)(n.code,{children:"bytes"})," content."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Fallback:"})," If a ",(0,s.jsx)(n.code,{children:"DataFrame"})," is mapped to an unsupported extension, it defaults to writing as ",(0,s.jsx)(n.code,{children:".csv"}),". Other unsupported data types will cause an error during export."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Security Note:"})," Output filenames are sanitized to prevent writing outside the target ",(0,s.jsx)(n.code,{children:"output_path"})," directory (e.g., paths like ",(0,s.jsx)(n.code,{children:"../other_dir/file.txt"})," or ",(0,s.jsx)(n.code,{children:"/absolute/path/file.txt"})," are disallowed)."]}),"\n",(0,s.jsxs)(n.h2,{id:"6-in-memory-transformation-transform-method",children:["6. In-Memory Transformation (",(0,s.jsx)(n.code,{children:"transform"})," method)"]}),"\n",(0,s.jsxs)(n.p,{children:["If you only need the transformed data in memory (e.g., for further processing in Python) without writing files, use the ",(0,s.jsx)(n.code,{children:"transform"})," method. It accepts the same ",(0,s.jsx)(n.code,{children:"sdif"})," parameter types as the ",(0,s.jsx)(n.code,{children:"export"})," method."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Get the transformed data as a dictionary {filename: data_object}\ntransformed_data = transformer.transform(sdif="input.sdif")\n\n# Access the data\ndf_invoices = transformed_data.get("processed_invoices.csv")\nif df_invoices is not None:\n    print(f"Processed {len(df_invoices)} invoices in memory.")\n\n# If you need to export this data later, you can use the _export_data method\n# transformer._export_data(data=transformed_data, output_path="output/dir")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"7-advanced-configuration",children:"7. Advanced Configuration"}),"\n",(0,s.jsxs)(n.p,{children:["You can customize the ",(0,s.jsx)(n.code,{children:"CodeTransformer"})," during initialization:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"function_name"})," (str, default ",(0,s.jsx)(n.code,{children:'"transform"'}),"):"]})," The name of the function to call when ",(0,s.jsx)(n.code,{children:"function"})," is provided as a code string or file path. Ignored if ",(0,s.jsx)(n.code,{children:"function"})," is a callable or uses the ",(0,s.jsx)(n.code,{children:"@transformation"})," decorator (which sets the name automatically)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"extra_context"})," (Dict[str, Any], default ",(0,s.jsx)(n.code,{children:"{}"}),"):"]})," A dictionary of arbitrary Python objects that will be passed as the ",(0,s.jsx)(n.code,{children:"context"})," argument to your transformation function (if it accepts two arguments). Useful for passing parameters, configurations, or shared objects."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"db_schema_prefix"})," (str, default ",(0,s.jsx)(n.code,{children:'"db"'}),"):"]})," The prefix used for default schema names (",(0,s.jsx)(n.code,{children:"db1"}),", ",(0,s.jsx)(n.code,{children:"db2"}),", ...) when a ",(0,s.jsx)(n.em,{children:"list"})," of SDIF paths is provided as input. Ignored if input is a single path, a dictionary, or an ",(0,s.jsx)(n.code,{children:"SDIFDatabase"})," instance."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"code_executor"})," (CodeExecutor, optional):"]})," In production, you can plug a different execution backend (e.g., a sandboxed environment with E2B). Defaults to ",(0,s.jsx)(n.code,{children:"LocalCodeExecutor"}),", which runs the code in the current Python process."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Example with Context and Custom Prefix:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Transformation function accepting context\ndef process_with_context(conn, context):\n    discount = context.get(\'discount_rate\', 0.0)\n    df = pd.read_sql_query(f"SELECT * FROM {context[\'schema\']}.data", conn)\n    df[\'discounted_price\'] = df[\'price\'] * (1 - discount)\n    return {"discounted_data.csv": df}\n\n# Instantiate with context and custom prefix for list input\ntransformer = CodeTransformer(\n    function=process_with_context,\n    extra_context={"discount_rate": 0.15, "schema": "src1"}, # Pass context\n    db_schema_prefix="src" # Input list schemas will be src1, src2...\n)\n\n# Run with a list of SDIFs\ntransformer.export(\n    sdif=["data1.sdif", "data2.sdif"],\n    output_path="output/context_example"\n)\n# SQL inside function will use \'src1.data\' because of context[\'schema\']\n'})}),"\n",(0,s.jsx)(n.h2,{id:"8-error-handling",children:"8. Error Handling"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Errors during the execution of the transformation code (e.g., SQL errors, Python exceptions within your function) are caught and re-raised as an ",(0,s.jsx)(n.code,{children:"ExportError"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Errors during file I/O (writing outputs) are also raised as ",(0,s.jsx)(n.code,{children:"ExportError"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Configuration errors (e.g., invalid input types, non-existent input files) typically raise standard Python exceptions like ",(0,s.jsx)(n.code,{children:"TypeError"}),", ",(0,s.jsx)(n.code,{children:"ValueError"}),", or ",(0,s.jsx)(n.code,{children:"FileNotFoundError"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Syntax errors in code strings/files might raise ",(0,s.jsx)(n.code,{children:"ValueError"})," during initialization or ",(0,s.jsx)(n.code,{children:"ExportError"})," during execution."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Always wrap calls to ",(0,s.jsx)(n.code,{children:"transform"})," or ",(0,s.jsx)(n.code,{children:"export"})," in a ",(0,s.jsx)(n.code,{children:"try...except"})," block to handle potential failures gracefully."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}}}]);